# -*- coding: utf-8 -*-
"""이커머스_코호트 분석.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hsQBcKiAymTD4KSFAZidtGqBTvu3QPTL

**코호트 분석**
---
> **목차(Context)**

* 프로젝트 Summary
* 문제상황 Introduction
* process.01
* process.02
* process.03

## **프로젝트 Summary**
---

> **프로젝트명**

```
▶ Ecommerce 코호트 분석
```  

> **프로젝트유형**

```
▶ 이커머스 데이터 활용 코호트 분석

```

> **학습목표**

```
▶ 코호트 분석의 원리와 방법론에 대한 깊은 이해 습득
▶ 이커머스 데이터의 특성을 파악하고, 고객의 재구매, 이탈 등의 패턴을 분석하는 능력 개발
▶ 다양한 기간과 세그먼트에 따른 고객 행동의 변화를 시각적으로 표현하는 능력 향상
▶ 코호트 분석 결과를 바탕으로 마케팅 및 영업 전략을 제안할 수 있는 능력 개발
```

> **예상 결과물**

```
▶ 각 코호트별 재구매, 이탈률 등의 지표 분석 보고서
▶ 시간에 따른 고객 행동 변화를 나타내는 시각화 자료 (히트맵, 그래프 등)
▶ 주요 코호트의 특징 및 추세 파악에 대한 문서화
▶ 분석 결과를 기반으로 한 마케팅 및 영업 전략 제안서
```

## **문제상황 Introduction**
---
> **시나리오**

```
기업 Zeta는 자사의 이커머스 사이트에서의 고객 행동 패턴을 더 잘 이해하고자 한다. 최근, 고객들의 재구매율이 떨어지는 경향을 보이며, 이에 대한 원인과
대응 방안을 찾고자 한다. 마케팅 팀은 고객의 재구매 및 이탈 패턴을 분석하기 위해 "코호트 분석" 프로젝트를 시작하기로 결정한다.
마케팅팀은 고객들의 최초 구매 월을 기준으로 코호트를 형성한다. 예를 들어, 1월에 처음 구매한 고객들, 2월에 처음 구매한 고객들 등으로 그룹을 나눈다.
이러한 코호트 그룹별로 이후의 월별 재구매율, 이탈률 등의 지표를 분석한다. 이 때, CohortIndex라는 지표를 활용하여 각 코호트가 유입된 이후로 지난
개월 수를 표시한다.
프로젝트 진행 중, 마케팅팀은 특정 코호트에서 재구매율이 높게 나타나는 패턴과 이탈률이 높게 나타나는
패턴을 발견한다. 이러한 분석을 통해, 그 원인이 무엇인지, 어떤 마케팅 전략이나 프로모션 활동이 효과적이었는지 파악하고자 한다.
```  

> **문제정의**

```
▶ 고객들의 재구매율이 떨어지는 경향을 발견
```  

> **기대효과**

```
▶ 어떤 마케팅 전략이나 프로모션 활동이 효과적이었는지 파악
```

> **해결방안**

```
▶ 월별 재방문율과 매출을 코호트 분석을 통해 전체적인 흐름을 파악
```

> **데이터 살펴보기**

|Column|Description|
|:---|:---|
|InvoiceNo|송장번호|
|StockCode|재고코드|
|Description|상세설명|
|Quantity|수량|
|InvoiceDate|송장날짜|
|UnitPrice|개당가격|
|CustomerID|고객ID|
|Country|나라|
"""

# ▶ Warnings 제거
import warnings
warnings.filterwarnings('ignore')

# ▶ Google drive mount or 폴더 클릭 후 구글드라이브 연결
from google.colab import drive
drive.mount('/content/drive')

# ▶ 경로 설정 (※강의자료가 위치에 있는 경로 확인)
import os
os.chdir('/content/drive/MyDrive/파이썬 데이터분석/개인 프로젝트/이커머스 코호트 분석')
os.getcwd()

# ▶ Data read
import pandas as pd
df = pd.read_csv('Ecommerce.csv', encoding='ISO-8859-1')
df.head()

"""# process.01

### · Data 전처리  
---
* 수집된 데이터의 기본 정보들을 확인  

  (1) Data shape(형태) 확인

  (2) Data type 확인

  (3) Null값 확인 (※ 빈 값의 Data)
"""

# data shape
print('df',df.shape)

# data type
df.info()

# invoiceData가 object인것을 확인
# dataType으로 변경 시작!

df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'])
df.info()

# Null값 확인
print(df.isnull().sum())

#df (541909, 8) 중에 'CustomerID'의 135080행이 null값;; -> 일단 InvoiceNo에는 null값이 없으니 보류
# Description의 null값에는 none으로 치환해준다.

df['Description'].fillna(value='None', inplace= True)

df.isnull().sum()

null_rows = pd.DataFrame(df[df.isnull().any(axis=1)])
null_rows['InvoiceNo'].nunique()
# customerId의 주문건수는 3710건... 한 두사람은 절대 아닌거같은데 이 데이터를 무시해도 될까?

min_date = df['InvoiceDate'].min()
max_date = df['InvoiceDate'].max()
min_date

max_date

"""1년 사이에 3710건을 혼자 주문하는 사람은 없으므로 customerId가 null인 데이터는 제외하고 분석에 들어가는게 신뢰도가 더 높을듯"""

# customerId null값 삭제
df = df.dropna(subset=['CustomerID'])
df.isnull().sum()

"""### · cohortIndex 컬럼 생성
---
* 코홀트 분석을 하기 위한 컬럼 생성
"""

# 각 customerId별 첫 구매일 계산
df['first_month'] = df.groupby('CustomerID')['InvoiceDate'].transform('min').dt.to_period('M')

# 각 구매가 이루어진 날짜를 "OrderCycle"이라는 열에 삽입하여 데이터를 준비
df['OrderCycle'] = (df['InvoiceDate'].dt.to_period('M'))

df

"""# process.02

### · 월별로 구매 고객 데이터 치환
---
* 월별로 구매 고객을 볼 때 총 2가지 데이터를 계산해야 한다.

- 첫 번째. 주기별 구매한 User의 수 계산

- 두 번재. 주기별 구매한 금액의 계산
"""

## 주기별 구매 User 계산
co1 = df.groupby(['first_month', 'OrderCycle']).CustomerID.nunique()
co1 = co1.reset_index()
co1.rename({'CustomerID': 'TotalUsers'}, axis = 1, inplace = True)

## 주기별 구매 금액 계산
co2 = df.groupby(['first_month', 'OrderCycle']).UnitPrice.sum()
co2 = co2.reset_index()
co2.rename({'UnitPrice': 'PurchaseAmnt'}, axis = 1, inplace = True)

## 데이터의 병합
co = co1.merge(co2, on = ['first_month', 'OrderCycle'])
co.head()

df.info()

# 기간 카운트하는 열 추가
co['CohortIndex'] = (co['OrderCycle'] - co['first_month'])
co

import re

co['CohortIndex'] = co['CohortIndex'].apply(lambda x: int(re.search(r'\d+', str(x)).group()) if re.search(r'\d+', str(x)) else None)
co['CohortIndex'].fillna(value= 1.0, inplace= True)
co



"""### · 코호트 데이터 형태 최종 완성
---

"""

## 첫 번째. 재방문율 계산을 위한 Pandas Unstack 활용
co_retention = co.set_index(['first_month', 'CohortIndex'])
co_retention = co_retention.TotalUsers.unstack(1)
retention = co_retention.div(co_retention[0],axis = 0)
retention

## 두 번째. 구매 규모 형태 치환을 위한 Pandas Unstack 활용
co_purchase = co.set_index(['first_month', 'CohortIndex'])
co_purchase = co_purchase.PurchaseAmnt.unstack(1)
co_purchase

"""# process.03

### · 코호트 분석 시각화
---
"""

import matplotlib.pyplot as plt
import seaborn as sns

## 재방문율 시각화 진행
plt.rcParams['figure.figsize'] = (30, 8)
sns.heatmap(retention, annot = True, fmt = '.0%')

plt.yticks(rotation = 360);

## 구매 규모 시각화
plt.rcParams['figure.figsize'] = (30, 12)
sns.heatmap(co_purchase, annot = True
            , fmt = '.0f'
           )
plt.yticks(rotation = 360);

"""#### 분석 결과 정리
- 2010.12 월에 첫 구매를 한 고객군들이 retention이 제일 좋음
- 2011.01 월 이후로 부터는 첫구매 보다는 구매규모가 다음달이 확 줄어듦 (특히 2011.10월이 심함)

# 🥹분석 회고

- KPT 회고

> K [현재 만족 및 이어갔음 하는 부분]
```
프로젝트 완료 후에도 간직하고 싶은 잘했던 것
```
- 코홀트 분석의 개념과 코드를 실습해볼 수 있어서 좋은 경험이였다
- 다양한 데이터 타입(특히 날짜데이터)을 접해볼 수 있었다

> P [개선이 필요한 부분]
```
프로젝트 중 겪었던 어려움
프로젝트 완료 후에도 아쉬움으로 남는 것
```
- 날짜 데이터 중에 period[M]을 처음 접해봤는데, 내가 평소에 사용하던 datetime으로의 데이터 형태 변환하는것에 어려움을 겪었다. 쳇지피티나 구글링을 통해서 해결해보고자 했지만 다 안되고 실패;; 결국 람다 함수를 통해 강제로 숫자만 추출해서 float 형태로 변환시킨게 아쉬움이 남았다.     

> T [P에 대한 해결책]
```
Problem 중 해결된 사항에 대한 해결 방법
해결되지 않은 사항에 대한 피드백
```

- 데이터 형태에 대한 개념이 아직 부족하다고 절실히 느끼게 해줬던 프로젝트였다. 내가 부족한 부분을 또 하나 알게 되었으니 무엇을 공부해야할지, 어떻게 공부해야할지 알게 되어서 방향성을 잡을 수 있을것같다.. 화이팅
"""

